============================================================= TENSORFLOW


*Para o tensorflow rodar a operação, antes ele cria um mapa. Para rodar o mapa, voce precisa de uma sessao:
	Sess = tf.compat.v1.Session()#Criando um objeto da classe sessão. Repare qua apartir da versao 2.0.0 operacoes com constante nao entram no mapa
	
*Antes de rodar uma sessao, voce precisa inicializar todas as variaveis com o valores desejados:
		init = tf.compat.v1.global_variables_initializer()#Para inicializar as variaveis
	Em uma sessao, rode o 'init'


*n_nomes = np.unique(banco de dados de labels)#Retorna quantas Labels unicas possui nesse dataset

*a = tf.constant()#Cria uma constante.
*a = tf.zeros()#Cria uma variavel inicializada em zero com o shape designado e nome designado
*a = tf.ones()#Cria uma variavel inicializada em 1 com o shape designado e nome designado
*a = tf.random_normal()#Cria uma variavel inicializada em um valor random maior que 0 ate 1 com o shape designado e nome designado
*a = tf.Variable()#Cria uma variavel inicializada em zero com o shape designado e nome designado

*x_image = tf.reshape(x,[-1,28,28,1])#Conv layer preciso do formato [num_images,img_h,img_w,n_channel] Nossa figura tem 28x28x1 preto/branco

*y_true_class = tf.argmax(y_true)

*target_val = tf.one_hot(target_val,10)#Hotenconding o target data

*Em um modelo, uma variavel nunca consegue ser recuperada! Ela consegue ser compativel por nome e entao copiada em outra de mesmo nome (load):
	tf.compat.v1.get_variable()


*Operaçoes CNN
	*layer = tf.nn.max_pool(input = layer,
		           ksize = [1,2,2,1],#A matriz do maxpool percorre apenas 1 imagem, de 2 em 2 pixels em comprimento e altura e em apenas 1 canal
		           strides = [1,2,2,1],#O stride precisa ser dois, para efetuar o comportamento padrao do maxpool
		           padding = 'SAME')#Consideramos as bordas na jogada
	*layer = tf.nn.conv(input = x,#O input deve ter formato [numero_de_imagens,altura_da_imagem,comprimento_da_imagem,numero_de_canais]
		       filters = weights,#Nao existem filtros prontos!!, Os filtros sao variaveis pesos que serão otimizadas de acordo com a imagem! São filtros personalizados para a imagem! São pesos compartilhados! Por isso a CNN possui pouco carater espacial!
		       strides = [1,1,1,1],#O stride é como o filtro se locomove por estes diferentes shape do input
		       padding = 'SAME')#mantendo como resultado o mesmo shape, ou seja, a borda entrara na jogada
	*crossentropy = tf.nn.softmax_cross_entropy_with_logits(logits = layer_fc2, labels = y_true)#Esta funcao executa o softmax e ja calcula o erro cross entropy das categorias.


*y_pred = tf.nn.softmax(layer_fc2)#Ao inves de aplicar Relu aplicamos softmax

*Dado um tensor:
	layer_shape = layer.get_shape()#Coleta shape 
	num_features = layer_shape[1:4].num_elements()#Multiplica os elementos entre si


*correct_pred = tf.equal(y_pred_class,y_true_class)#Cria um vetor de booleanos dizendo se acertou ou nao

*accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))#Quero a media do vetor de booleanos == acuracia 

*Para passar o valor de uma variavel durante o treinamento de um modelo, voce usa um placeholder
	tf.compat.v1.placeholder()
	
	Tive um problema: ao usar o placeholder surgiu um error: tf.placeholder() is not compatible with eager execution. A solução é dar disable no eager execution:
		tf.compat.v1.disable_eager_execution()#TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs


*Para criar variaveis em diferentes escopos:
	with tf.compat.v1.variable_scope('escopo1'):
	    var = tf.Variable(tf.compat.v1.random_normal([1],),name = 'var1')#Adicionando outra variavel de mesmo nome so que em escopo diferente
	    
*crossentropy = tf.nn.softmax_cross_entropy_with_logits(logits = layer_fc2, labels = y_true)#Esta funcao executa o softmax e ja calcula o erro cross entropy das categorias.
*cost = tf.reduce_mean(crossentropy)#Vou otimizar a media do cross entropy
*Optmizer = tf.compat.v1.train.AdamOptimizer(learning_rate= 1e-4).minimize(cost)# Falando para o otimizador Adam otimizar o custo à um learning rate de 0.0001

*Operaçoes:

	x = tf.multiply(a,b)#Multiplica aritmeticamente dois elementos
	x = tf.add(a,b)#Soma dois elementos


*Multiprocessameto:
		from tensorflow.python.client import device_lib, print(device_lib.list_local_devices())#Printa todos os processadores possiveis para processamento
		with tf.device('/CPU:0'):
			<ACOES>
	Para configurar uma sessao do device:
		with tf.compat.v1.Session(config = tf.compat.v1.ConfigProto(log_device_placement=True)) as sess:
		

*Tensorboard:
	Criamos um objeto para escrever um arquivo:
		tensorboard_file =tf.compat.v1.summary.FileWriter( logdir, sess.graph)
	Dai vai surgir uma pasta no diretorio dito com um arquivo dentro!
	Abrir aquele diretorio e abrir terminal. No terminal chamar:
		tensorboard --logdir=<nome_da_pasta_ou_arquivo>
	Vai surgir um link... Nao fechar o server e colar aquilo no browser... Pronto!!



============================================================================================== Keras: ============================================================================


*model = keras.models.Sequential()#Criando objeto que cria um modelo sequencial

*model.add(keras.layers.Dropout(0.5))#Para colocar uma taxa de dropout na layer anterior
	

*model.summary()#Plota o summary sequencial do objeto modelo

*Antes de usar o keras na gpu, vc precisa configurar o proto.
	*a.astype('float32')#Mexendo com a precisao da variavel


*target_train = keras.utils.np_utils.to_categorical(target_train,10)#Hotenconding an target


*model.add(keras.layers.Dense(10, input_dim = 784, activation = 'softmax'))

*model.add(keras.layers.BatchNormalization())#Para normalizar o batch antes de ele entrar na funcao de ativação. Quando usar normalização, nao podemos usar o activation no Dense e sim a funcao add activation

*model.add(keras.layers.Activation('relu'))

*model.add(keras.layers.Flatten())#Torna dados em formato 3D ou 2D ou 4D em um vetor ordenado de dados.

*model.compile(optmizer = 'sgd', loss = 'categorical_crossentropy', metrics=['accuracy'])#Stochastic Gradient Decent, crossentropy, e acurácia - esse compile é as configuraçoes de treinamento.

*score = model.evaluate(input_val, target_val, verbose=0)#Avaliando o modelo para o database de validaçao silenciosamenteo score retornando tera dois floats o primeiro é o erro e o segundo a accuracy


*history = model.fit(input_train, target_train, batch_size = batch, epochs = epochs , verbose = 1 , validation_data = (input_val,target_val), callbacks = [<o nome do objeto de uma funcao ai>]) #Treinando o modelo  com esses endereços... Verbose = 0 : silencioso, Verbose = 1 :barra de progresso com epochs em cada linha, Verbose = 2 : Somente os resultados de cada epoca em cada linha no final de cada epoca ele registra um callback e executa o objeto. O history é uma varaivel para armazenar o callaback automatico do fit.	
	O objeto history tem uma funcao history que é um dicionario
		uma das chaves é 'accuracy' -  qual a acuracia por cada epoca
		Outra chave é 'val_accuracy'
		Outra chave é 'loss'
		Outra chave é 'val_loss'


Callback é usado para parar o treinamento da rede caso ele alcance o resultado planejado.
	*keras.callbacks.Callback()

É possivel recordar todos os valores ja treinados em
	*keras.callbacks.History()
	*https://keras.io/callbacks/       para ensinar como usar
	Existe um callback automatico... Se voce colocar a funcao fit do modelo atribuindo a uma variaver, por exemplo, history, a funcao history.history sera um dicionaro de recordaçao do metrics.

Checkpoint: sua rede é salva periodica por uma funcao callback. Ela consegue ser loadada e continuar treinando mais a frente
	*keras.callbacks.ModelCheckpoint(filepath,monitor = 'val_loss', verbose = 0, save_best_only = False, save_weights_only=False, mode = 'auto', period = 1)
		usar em: *model.fit(callbacks = [checkpoint])


Para salvar os pesos ou modelo:
	*model.save_weights(filepath,overwrite=True)# A extensao deve ser h5
	*model.save(filepath,overwrite=True)# A extensao deve ser h5
	*model = keras.models.load_model('/home/salomao/Desktop/saved.h5')#para loadar uma rede


Para usar o modelo loadado ou o treinado so usar
	*pred = model.predict(x)#tenha em mente que x tem que ter uma dimensao a mais, do batch
	Em casos de onehotencoded, voce pode usar a funcao a baixo para descobrir qual a coluna é a sobresalente.		
		np.argmax(pred[0])


Para criar data augmentation no fit, usamos:
	*datagen = keras.preprocessing.image.ImageDataGenerator(
	    rescale = 1./255,
	    featurewise_center=True,
	    featurewise_std_normalization=True,
	    rotation_range=45,
	    width_shift_range=0.2,
	    height_shift_range=0.2,
	    horizontal_flip=True)
	*datagen.fit(train_data)
	*history = model.fit(datagen.flow(train_data, label_array_train, batch_size=batch_size),epochs=epochs, verbose=1, validation_data=(val_data,label_array_val))


# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(train_data)



Posso criar modelos não sequenciais usando funcoes:
	*layer_in = keras.layers.Input(shape= (500,500,3))#Para criar a entrada do modelo.
	*conv1_l1  = keras.layers.Conv2D(64, kernel_size=3, activation= 'relu')(layer_in)#Para criar um conv layer que recebe input da layer_in
	*pool1_l1  = keras.layers.MaxPool2D()(conv1_l1)#Para criar um maxpooling com input da layer conv1_l1
	*flat_l1 = keras.layers.Flatten()(pool2_l1)#Recebe input do pool2_l1
	*concatenate1 = keras.layers.concatenate([flat_l1,flat_l2,flat_l3])#Junta todos os dados na ordem especificada de inputs
	*dense1 = keras.layers.Dense(30,activation='relu')(concatenate1) #Criar uma rede densa que pega a juntaçao de todas anteriores, juntadas na concatenate1
	*model = keras.models.Model(inputs=layer_in,outputs=layer_out)#Para criar um modelo com entrada no layer_in e saida no layer_out treinamos o modelo normalmente.
	



==================================================================================== scipy ====================================================================

*img_g_edge1 = scipy.signal.convolve2d (img_g,kerne_edge_det1, 'valid') #A diretiva 'valid', fala pra ele diminuir a diemnsao (nao preencher com zeros), os dados da borda é descartado



==================================================================================== Scikit-image================================================

*skimage.data.coffee()#Literalmente uma foto de café kkkkkkk

*img = skimage.color.rgb2gray(img)


=============================================================================== SKLEARN ===========================================================================


*Para dar shuffle randomico em um input e target juntos:
	X = np.array([[1., 0.], [2., 1.], [0., 0.]])
	y = np.array([0, 1, 2])
	X,y = sklearn.utils.shuffle(X,y, random_state=0)#Os vetores devem estar no formato numpy.






======================================================================================= Pandas ====================================================================


*Para ler formato .csv
	pandas.read()



======================================================================================== PICKLE ==========================================================


Biblioteca para salvar qualquer variavel.
*Para gravar:
	pickle_arq = open('directory','wb')
	pickle.dump(var,pickle_arq)
*Para loadar:
	pickle_arq = open('directory','rb')
	var = pickle.load(pickle_arq)	



==================================================================================== OPENCV ==============================================================
*img = cv2.imread(path, flag)#Retorna um numpy array em BGR com a matriz imagem
	cv2.IMREAD_COLOR: It specifies to load a color image. Any transparency of image will be neglected. It is the default flag. Alternatively, we can pass integer value 1 for this flag.
	cv2.IMREAD_GRAYSCALE: It specifies to load an image in grayscale mode. Alternatively, we can pass integer value 0 for this flag.
	cv2.IMREAD_UNCHANGED: It specifies to load an image as such including alpha channel. Alternatively, we can pass integer value -1 for this flag.

*img = cv2.cvtcolor(img,cv2.COLOR_BGR2RGB)#Converte do modelo BGR para RGB

*cv2.imshow('nome da tela',var_img)#Printa na tela a imagem no formato BGR


===================================================================================== OUTROS FEATURES ================================================================
*icrawler#Uma biblioteca que permite o download de varias imagens do google

*labellmg #App para fazer a legenda de imagens - usado na classificacao

========================================================= PARAMETROS DE CONSTRUÇAO =====================================================

*Otimizadores de primeira ordem:
	Batch Gradient Descent: sensível à minimos locais. Ou seja, Pode ser que nao chegue ao minimo global dependendo da quantidade de database.

	Stochastic Gradient Descent: Os parametros flutuam bastante com o entuito de descobrir o minimo global ou minimos locais promissores. O problema deste tipo de algoritmo é que por causa disso ele demora a convergir ou simplesmente nao converge. Quando ele desenvolver este tipo de flutuação excessiva é recomendado diminuir o learning rate.

	Mini-batch Gradient Descent: é o meio termo entre o SGD e o BGD. Em redes neurais neutras é recomendado sua utilização. Convergencia é rapida.

*Otimizadores de segunda ordem:
	Sao funcoes mais custosas para o processador porém tem menos dificuldades em lidar com regioes de minimos locais.

	Momentum(y): acelera a queda do gradiente, ignora gradientes irrelevantes, filtrando altas variações

	Nesterof Acelerated Gradient(NAG): Regula o momento fazendo com que a flutuaçao em torno do ideal seja filtrado

	ADAGRAD: learning rate se adapta baseado nos parametros. Parametros ultra variantes tem learning rate menor e os parametros pouco ou invariantes (quando fala-se em variante - flutuante), tem maior learning rate. Nao faz sentido tunar o learning rate. O problema é que o learning rate esta sempre decaindo, e portanto, toma mais tempo.

	RMSPROP(Root Mean Square Propagation): o ADAGRAD quase nunca converge, ou toma demasiado tempo. RMSprop aprende de forma mais flutuante, porem, converge mais proximo do minimo global.

	ADAM(Adaptive Moment Estimation): Adapta o learning rate para cada parametro, nunca para de aprender, nao sofre problemas de variações excesivas.



*Non convex funtion: 
	Funcao cheia de minimos locais
		*Cross-entropy: Sempre positiva, onde a perfeiçao é zero. Consegue ser utilizada para calcular o erro em mais de uma categoria. 
		
*Convex funtion:
	Funcao so tem minimo global
		*Hinge


*Regulando uma rede neural (Regularization of a neural network): Achar o menor modelo possivel evitando os dois problemas a seguir.
	Overfitting: ocorre quando a rede é exageradamente complexa e portanto sobre-reage a qualquer alteração de parametro de entrada. Ela vai decorar o train_data e errar a validação.

	Underfitting: Quando nem o train_data e a val_data consegue aprender.


	Em redes neurais É SEMPRE RECOMENDADO EVITAR PESOS MAIORES... Acredite em VARIOS PESOS MENORES. Vamos consultar a penalidade. LASSO, RIDGE and ELASTICNET
		L1: Soma absoluta dos valores de coeficiente
		L2: É a soma dos coeficientes ao quadrado
	*Somente L1 é o metodo de LASSO
	*Somente L2 é o metodo do RIDGE REGRESSION
	*Os dois é o metodo ElasticNet

	*Data augmentation: Serve para evitar overfitting problems

*Funçoes de ativação:
	É fazer uma transformação e tornar a resolução nao linear. A maioria dos problemas nao sao lineares

		*FUNCAO LINEAR: O gradiente descente é constante e portanto gera uma variação alta de aprendizado. Alem do mais por ser uma funcao linear, nao se consegue aprender padroe nao-lineares, ou naturais.
		*Sigmoid: nao-linear, pode representar  probabilidades, porem, para valores muitos altos ou pequenos, temos vanishing gradients, e portanto, a rede para de aprender
		*Tanh: nao linear, temos valores negativos e tambem temos problemas de vanishing gradient.
		*ReLU: nao linear e somente ajuda em problemas esparsos, onde temos vario
s dados que nao ajudam valores negativos sao zero. Os valores negativos nao possuem gradiente e portanto os pesos nao sao ajustados -> seu modelo fica fragilizado, varia muito, e chega em um minimo muito rapido - >  'dying RELU problem'.... Para arrumar ou diminuir o problema dos dying RELU recomenda-se diminuir o learning rate
		*Leaky RELU: nao possui a area zerada e sim um valor muito baixo.
		*ELU : uma função exponencial que nao tem zero porem toma forma do relu. 




*Em um teste realizado, mostrou que a funcao sigmoid teve problemas em convergir. RELU, convergiu bem, porem ELU foi melhor.



*Convolutional NetWorks, parametros:
	*Filtro/kernel/Feature Detector
	*Convolved Filter, activation map, Feature map: output do filtro passando pela imagem
	*Recptive region: regiao onde o filtro opera o dot operation
	*Depth: numero de filtros
	*Depth_colum: neuronios que apontam para o mesmo campo receptivo
	*Stride: O passo que o filtro da conforme caminha pela sua imagem
	*zero-padding = mantem a informação das bordas
	*relu_layer = Torna valores negativos em zeros
	*pooling = reduz a imagem reduzindo a complexidade da figura
		max_pooling mantem o valor maximo de um filtro em uma regiao. Usado para diminuir a massa de dados.
	*Dilation : Quais bit vc utiliza para fazer as contas.
	Em redes convolucionais o numero de filtros mencionados, são pacotes de pesos que serão treinados e são compartilhados sobre toda a figura!! Não existem filtros personalizados e no final das contas o tamanho do kernel é mais decisivo que a quantidade deles.

*Batch normalization -- Estabiliza o aprendizado, aumentando-o.

*Dropout: Forma eficaz de evitar overfitting. Ele desliga um percentual de neuronios do layer interior. Desliga de tal forma a fazer que os pesos ficam menores possiveis (usa lasso regurazator)

*Fully connected layer: normal neural network.




============================================================================================ OBJECT DETECTATION -=============================================================


	Primeira skill necessaria:
		-GROUND TRUTH - o ato de pegar uma imagem e criar um label com as coordenadas x,y,w,h,label

		-ARCHITECTURE- 
			-CONV NET
			- Duas redes neurais distintas - 
				-Uma para classificar o label
				-Outra chamada bounding regressor
		Transfer learning


=========================================================================  Faster-RCNN

	A imagem passa paralelamente por dois processos:
		-Anchors: Caixas geradas em diversos tamanhos - No caso, 9 ancoras, que andam pela imagem (stride) seguindo um centro. Surgem muitas possibilidades, e passar todas as figuras demandaria muito tempo... POR ISSO existe o RPN - > RANKS REGION BOX --.
			RPN- 
		-NON-MAX_SUPRESSION _ Aparecerao varias caixas no envolto do objeto. Elas irao se unir e formar uma caixa só -  que tem maior probabilidade.
		-ROI max pooling - Reduz a imagem uma matriz de um tamanho PADRAO.!!!
		-INtecection over UNION - mede a area da intercecçao dividida pela area total. Medida de precisao
		-mAP - mean everage precision - 
		


Tensorflow object detection API:


	intall:
		https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md
		>>cd model/research
		>>pip install .





======================================================================== YOLO




